common:
    model:
        name: RandLANetv1
        dataset: Semantic3D
        feature_channel: 6
    logs:
        base_logger:
            path: log/log.txt
        tensorboard_logger:
            path: log
    snapshot:
        save_path: snapshot
    load:
        load: False
        path: ./ckpt_best_model.pth.tar
        type: recover
train:
    # batch_size = 4  # batch_size during training
    # val_batch_size = 16  # batch_size during validation and test
    # train_steps = 500  # Number of steps per epochs
    # val_steps = 100  # Number of validation steps per epoch
    # max_epoch = 100  # maximum epoch during training (100*500)
    # learning_rate = 1e-2  # initial learning rate
    # lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
    batch_size: 4
    workers: 4
    dataset:
        name: Semantic3DDataset
        mode: training
        data_path: /data/dataset/semantic3d
    optimizer:
        name: Adam
        betas: [0.9, 0.999]
        eps: 0.00000001
        weight_decay: 0.0001
    lr_scheduler:
        type: lr_scheduler_step
        step_size: 500
        gamma: 0.95
        base_lr: 0.01
    runner:
        name: iteration
        max_iter: 100000
        # test and save
        test_freq: 1000
        save_freq: 100000
        log_freq: 10
        snapshot_save_path: snapshot
test:
    batch_size: 2
    workers: 0
    dataset:
        testset:
            name: Semantic3DDataset
            mode: validation
            data_path: /data/dataset/semantic3d
