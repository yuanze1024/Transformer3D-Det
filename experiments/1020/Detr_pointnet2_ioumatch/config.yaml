common:
    model:
        name: votenet
        task_type: Scannetv2
        net_type: detr
        loss_type: matching_giou_bbox_directly
        num_target: 0
        num_input_channel: 0
        vote_factor: 1
        cluster_sampling: bbox_directly
        backbone:
            # name: votenet_backbone
            name: pointnet
        transformer:  # just for transformer
            position_embedding: sine
            input_dim: 3
            enc_layers: 2
            dec_layers: 2
            dim_feedforward: 2048
            hidden_dim: 288
            dropout: 0
            # dropout: 0.1
            nheads: 8
            num_queries: 40
            pre_norm: False
        loss_weight:
            matching_weight:
                heading_class_loss: 0
                heading_residual_loss: 0
                size_iou_loss: 10
                size_cdist_loss: 1
                cls_loss: 0
                obj_weight_choose(loss): 0
            loss_weight:
                heading_class_loss: 1  # heading angle
                heading_residual_loss: 10
                size_iou_loss: 10  # giou_loss = 1-giou
                size_cdist_loss: 1  # cdist(l2) loss
                cls_loss: 1  # obj class loss
                obj_loss: 5  # obj usage loss; weight=[0.2, 0.8]
    logs:
        base_logger:
            path: log/log.txt
        tensorboard_logger:
            path: log
    snapshot:
        save_path: snapshot
    load:
        load: False
        path: ./ckpt_best_model.pth.tar
        type: recover
train:
    batch_size: 8
    workers: 8
    dataset:
        name: Scannetv2
        split_set: train
        # data_path: C:\Users\ZLC\Desktop\pycodes\data\scannet_train_detection_data
        data_path: /data1/zhaolichen/data/scannet_train_detection_data
        augment: True
        # use_color: True
        # use_height: True  # use it as feature
    optimizer:
        name: AdamW
        betas: [0.9, 0.999]
        eps: 0.00000001
        weight_decay: 0.0001
    lr_scheduler:
        type: cosine
        T_max: 150000
        base_lr: 0.0001
    transform: None # TODO
    runner:
        name: iterBNDecay
        max_iter: 150000
        # test and save
        # test_freq: 1600
        test_freq: 1000
        save_freq: 16000
        log_freq: 10
        snapshot_save_path: snapshot
test:
    batch_size: 8
    workers: 4
    dataset:
        valset:
            name: Scannetv2
            split_set: val
            # data_path: C:\Users\ZLC\Desktop\pycodes\data\scannet_train_detection_data
            data_path: /data1/zhaolichen/data/scannet_train_detection_data
            # use_color: True
            # use_height: True  # use it as feature
