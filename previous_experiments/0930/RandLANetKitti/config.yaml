common:
    model:
        name: RandLANetv1
        dataset: SemanticKITTI
        feature_channel: 3
    logs:
        base_logger:
            path: log/log.txt
        tensorboard_logger:
            path: log
    snapshot:
        save_path: snapshot
    load:
        load: False
        path: ./ckpt_best_model.pth.tar
        type: recover
train:
    # batch_size = 4  # batch_size during training
    # val_batch_size = 16  # batch_size during validation and test
    # train_steps = 500  # Number of steps per epochs
    # lr_decays = {i: 0.95 for i in range(0, 500)}  # decay rate of learning rate
    batch_size: 6
    workers: 6
    dataset:
        name: SemanticKITTIAUGDataset
        test_id: 11
        mode: training
        data_path: /data/dataset/semantickitti/dataset/sequences_0.06
    optimizer:
        name: Adam
        weight_decay: 0
    lr_scheduler:
        type: lr_scheduler_step
        step_size: 3000
        gamma: 0.95
        base_lr: 0.001
    runner:
        name: iteration
        max_iter: 300000
        # test and save
        test_freq: 3000
        save_freq: 300000
        log_freq: 10
        snapshot_save_path: snapshot
test:
    batch_size: 6
    workers: 4
    dataset:
        validationset:
            name: SemanticKITTIAUGDataset
            test_id: 11
            mode: validation
            data_path: /data/dataset/semantickitti/dataset/sequences_0.06

